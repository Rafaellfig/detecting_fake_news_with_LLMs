{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak-Supervision Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVER\n",
    "import os\n",
    "os.chdir('d:\\\\Rafael\\\\MBA\\\\TCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "import pandas as pd\n",
    "from src.utils.api_utils import weak_supervision_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('data/X_test_fakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = [\"google:gemini-1.5-flash-002\"]\n",
    "models = [\"google:gemini-1.5-pro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_credibility_signals = {\n",
    "    'Evidence' : 'Does the article present any supporting evidence or arguments to substantiate its claims?',\n",
    "    'Bias' : 'Does the article exhibit any explicit biases in its content, tone, or perspective?',\n",
    "    'Inference' : 'Does the article make claims about correlation and causation?',\n",
    "    'Explicitly Unverified Claims' : 'Does the article contain claims that are explicitly unverified?',\n",
    "    'Personal Perspective' : 'Does the article express the authorâ€™s opinion on the subject?',\n",
    "    'Emotional Valence' : 'Is the language in the article extremely negative or extremely positive instead of neutral?',\n",
    "    'Polarising Language' : 'Does the article make use of polarising terms or make divisions into sharply contrasting groups or sets of opinions or beliefs?',\n",
    "    'Call to Action' : 'Does the article contain language that can be understood as a call to action, requesting readers to follow through with a particular task or telling readers what to do?',\n",
    "    'Expert Citation' : 'Does the article cite one or more experts in the subject?',\n",
    "    'Document Citation' : 'Does the article cite one or more studies or documents?',\n",
    "    'Source Credibility' : 'Does the article cite sources that are generally considered credible?',\n",
    "    'Incorrect Spelling' : 'Does the article have significant misspellings and/or grammatical errors?',\n",
    "    'Informal Tone' : 'Does the article make use of all caps or consecutive exclamation or question marks?',\n",
    "    'Incivility' : 'Does the article make use of stereotypes and generalizations of groups of people?',\n",
    "    'Impoliteness' : 'Does the article contain insults, name-calling, or profanity?',\n",
    "    'Sensationalism' : 'Does the article make use of sensationalist claims?',\n",
    "    'Low Credibility Organization' : 'This article was posted by a media outlet called {organization_name}.Is this source known for publishing false, unverified, or propagandistic articles?',\n",
    "    'Reported by Other Sources' : 'Was the story on this article reported by other reputable media outlets?'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando artigo 1 de 120...\n",
      "Erro ao processar o artigo 0, no modelo google:gemini-1.5-pro: The model response did not complete successfully.\n",
      "Finish reason: 3.\n",
      "Finish message: .\n",
      "Safety ratings: [category: HARM_CATEGORY_HATE_SPEECH\n",
      "probability: NEGLIGIBLE\n",
      "probability_score: 0.357421875\n",
      "severity: HARM_SEVERITY_LOW\n",
      "severity_score: 0.326171875\n",
      ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "probability: NEGLIGIBLE\n",
      "probability_score: 0.204101562\n",
      "severity: HARM_SEVERITY_LOW\n",
      "severity_score: 0.333984375\n",
      ", category: HARM_CATEGORY_HARASSMENT\n",
      "probability: MEDIUM\n",
      "blocked: true\n",
      "probability_score: 0.671875\n",
      "severity: HARM_SEVERITY_MEDIUM\n",
      "severity_score: 0.640625\n",
      ", category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "probability: NEGLIGIBLE\n",
      "probability_score: 0.34765625\n",
      "severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "severity_score: 0.189453125\n",
      "].\n",
      "To protect the integrity of the chat session, the request and response were not added to chat history.\n",
      "To skip the response validation, specify `model.start_chat(response_validation=False)`.\n",
      "Note that letting blocked or otherwise incomplete responses into chat history might lead to future interactions being blocked by the service.\n",
      "Processando artigo 2 de 120...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_respostas \u001b[38;5;241m=\u001b[39m \u001b[43mweak_supervision_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_credibility_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Rafael\\MBA\\TCC\\src\\utils\\api_utils.py:115\u001b[0m, in \u001b[0;36mweak_supervision_label\u001b[1;34m(articles, models, dict_credibility_signals, temperature, delay)\u001b[0m\n\u001b[0;32m    106\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    107\u001b[0m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'''\u001b[39m})\n\u001b[0;32m    110\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    111\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    112\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    113\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature\n\u001b[0;32m    114\u001b[0m )\n\u001b[1;32m--> 115\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m resposta \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resposta, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(YES|NO)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, resposta\u001b[38;5;241m.\u001b[39mupper()):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_respostas = weak_supervision_label(articles, models, dict_credibility_signals, delay=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_respostas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_respostas\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_respostas' is not defined"
     ]
    }
   ],
   "source": [
    "df_respostas.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_respostas.to_csv('results/resultados_weak_supervision_fakes_test_pro.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerodando para erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
